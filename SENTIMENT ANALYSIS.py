# -*- coding: utf-8 -*-
"""task4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10802O2Tz06Ndpio_a2RgnqcfOgVKj7To
"""

import pandas as pd
import re
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report

# Load the dataset
df = pd.read_csv('goemotions_1.csv')

# --- 1. Data Preprocessing: Create Simplified Sentiment Labels ---
positive_emotions = ['admiration', 'amusement', 'approval', 'caring', 'desire', 'excitement', 'gratitude', 'joy', 'love', 'optimism', 'pride', 'relief', 'surprise']
negative_emotions = ['anger', 'annoyance', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'fear', 'grief', 'nervousness', 'remorse', 'sadness']

# Map original 27 emotions to 3 classes
df['positive_label'] = df[positive_emotions].max(axis=1)
df['negative_label'] = df[negative_emotions].max(axis=1)

# Set classification priority: Negative > Positive > Neutral
df['sentiment'] = 'Neutral'
df.loc[(df['positive_label'] == 1) & (df['negative_label'] == 0), 'sentiment'] = 'Positive'
df.loc[(df['negative_label'] == 1), 'sentiment'] = 'Negative'

# Remove rows where 'neutral' was set AND a distinct emotion was also present, to simplify
df.loc[(df['neutral'] == 1) & ((df['positive_label'] == 1) | (df['negative_label'] == 1)), 'sentiment'] = 'Neutral_Conflicted'
df = df[df['sentiment'] != 'Neutral_Conflicted']

# --- 2. Data Preprocessing: Text Cleaning ---
def clean_text(text):
    text = text.lower()
    text = re.sub(r'[^\w\s]', '', text) # Remove punctuation
    return text

df['cleaned_text'] = df['text'].apply(clean_text)

# Prepare data for modeling
df_model = df[df['sentiment'].isin(['Positive', 'Negative', 'Neutral'])].copy()
X = df_model['cleaned_text']
y = df_model['sentiment']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# --- 3. Model Implementation: Feature Extraction (TF-IDF) and Model Training ---
vectorizer = TfidfVectorizer(max_features=5000)
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

model = LogisticRegression(max_iter=1000, random_state=42)
model.fit(X_train_vec, y_train)

# --- 4. Insights: Evaluation ---
y_pred = model.predict(X_test_vec)
report = classification_report(y_test, y_pred, zero_division=0)

print(report)